{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隠れマルコフモデル使って系列解析してみる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport\n",
    "`nltk`\n",
    "- 簡単に使えそうなコーパスだったので採用\n",
    "- `pip install nltk`でインストールできる（venvにはすでにインストール済み）\n",
    "\n",
    "`nltk`のサイズは大きいので, 必要な二つのデータだけ持ってきます\n",
    "- `treebank`\n",
    "    - 大規模注釈付きコーパス\n",
    "- `universal_tagset`\n",
    "    - 品詞タグのセット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/shibatakeigo/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/shibatakeigo/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件付き確率の計算\n",
    "HMMを作成するには\n",
    "1. $ P(\\bm{z_t} | \\bm{z_{t-1}}) $ \n",
    "2. $ P(\\bm{x_t} | \\bm{z_{t}}) $\n",
    "を用意すればOK.\n",
    "\n",
    "例えば, 今回使う文章（教科書からのパクリ）「Times flies like an arrow」だと\n",
    "1. $ P(V | V) $\n",
    "    V (動詞)の後にV（動詞）が出る確率\n",
    "2. $ P(V | \\rm{like}) $\n",
    "    likeという単語がV（動詞）である確率\n",
    "\n",
    "### 実装方針\n",
    "1. 単語とタグのペアを取得する\n",
    "- words_tags\n",
    "- 全部小文字にする（簡単化）\n",
    "2. 頻度分布を作成\n",
    "- 何回の頻度でその単語が出たのか？\n",
    "- frq_dis\\[word\\]\\[label\\]に`word`の品詞が`label`であった回数が格納される\n",
    "\n",
    "3. 条件付き確率分布を求める\n",
    "- $ P(品詞 | 単語) $で「単語」が出た時の「品詞」の確率を表す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Get pare of words and tags\n",
    "words = brown.words()\n",
    "words_tags = [(word.lower(), tag) for word, tag in brown.tagged_words(tagset='universal')]\n",
    "\n",
    "# print example\n",
    "print(words_tags[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': 296, 'BOS': 0, 'ADP': 3, '.': 0, 'ADV': 0, 'PRON': 0, 'X': 0, 'NUM': 0, 'CONJ': 0, 'DET': 0, 'PRT': 0, 'VERB': 1, 'ADJ': 0}\n"
     ]
    }
   ],
   "source": [
    "# 頻度分布を作成\n",
    "\n",
    "word_list = list(set([word_tag[0] for word_tag in words_tags]))\n",
    "tag_list = list(set([word_tag[1] for word_tag in words_tags] + [\"BOS\"])) # BOSは文の先頭を表すタグ\n",
    "\n",
    "freq_dist = {\n",
    "    word: {\n",
    "        tag: 0 for tag in tag_list\n",
    "    } for word in word_list\n",
    "}\n",
    "\n",
    "for word, tag in words_tags:\n",
    "    freq_dist[word][tag] += 1\n",
    "        \n",
    "print(freq_dist[\"times\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章に分割する\n",
    "# words = brown.words()\n",
    "sentences = []\n",
    "sentence = []\n",
    "for word_to_sentence in words_tags:\n",
    "    if word_to_sentence[0] != '.':\n",
    "        sentence.append(word_to_sentence)\n",
    "    else:\n",
    "        sentence.append(word_to_sentence)\n",
    "        sentences.append(sentence)\n",
    "        sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 条件付き確率分布を作成\n",
    "\n",
    "# それぞれのタグの出現回数を計算\n",
    "C_word = {\n",
    "    tag: 0 for tag in tag_list\n",
    "}\n",
    "\n",
    "for word_tag in words_tags:\n",
    "    C_word[word_tag[1]] += 1\n",
    "\n",
    "# BOSの出現回数を追加\n",
    "C_word[\"BOS\"] = len(sentences)\n",
    "\n",
    "# 条件付き確率を計算\n",
    "cfd = {\n",
    "    tag: {\n",
    "        word: freq_dist[word][tag] / C_word[tag] if C_word[tag] != 0 else 0 for word in word_list\n",
    "    } for tag in C_word.keys()\n",
    "}\n",
    "\n",
    "sum(cfd[\"ADP\"].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49346\n",
      "[('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n",
      "['BOS', 'DET']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences)) #文章の数を出力\n",
    "print(sentences[0]) #最初の文章を出力\n",
    "\n",
    "# 品詞のbigramを作成\n",
    "bigram = []\n",
    "for sentence in sentences:\n",
    "    for index in range(len(sentence)):\n",
    "        if index == 0:\n",
    "            bigram.append([\"BOS\", sentence[index][1]])\n",
    "        else:\n",
    "            bigram.append([sentence[index - 1][1], sentence[index][1]])\n",
    "\n",
    "print(bigram[0]) #最初の文章のbigramを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2941\n",
      "0.02031554370501361\n",
      "{'NOUN': 0.13861305880922467, 'BOS': 0.0, 'ADP': 0.12766992258744375, '.': 0.08235723260243992, 'ADV': 0.09477971872086896, 'PRON': 0.16337697077777327, 'X': 0.0005268917440116727, 'NUM': 0.017184776881611477, 'CONJ': 0.043063267539415556, 'DET': 0.22054472500303976, 'PRT': 0.03704454261743606, 'VERB': 0.040307218416892956, 'ADJ': 0.034531674299841934}\n",
      "49346\n"
     ]
    }
   ],
   "source": [
    "# C(品詞, 品詞)を計算\n",
    "tag_bigram = {\n",
    "    tag1: {\n",
    "        tag2: 0 for tag2 in tag_list\n",
    "    } for tag1 in tag_list\n",
    "}\n",
    "\n",
    "for word_tag1, word_tag2 in bigram:\n",
    "    tag_bigram[word_tag1][word_tag2] += 1\n",
    "    \n",
    "# 品詞間（隠れ状態）の遷移確率を計算 P(品詞 | 品詞)\n",
    "transition_pro = {\n",
    "    tag1:{\n",
    "        tag2: tag_bigram[tag1][tag2] / C_word[tag1] if C_word[tag1] != 0 else 0 for tag2 in tag_list\n",
    "    } for tag1 in tag_list\n",
    "}\n",
    "\n",
    "# C(ADP | ADP)\n",
    "print(tag_bigram[\"ADP\"][\"ADP\"])\n",
    "# P(ADP | ADP)\n",
    "print(transition_pro[\"ADP\"][\"ADP\"])\n",
    "print(transition_pro[\"BOS\"])\n",
    "print(C_word[\"BOS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbiアルゴリズム\n",
    "与えられた観測系列（ここでは単語）を元に, 隠れ状態（ここでは品詞）の最も確からしい系列を求めたい.\n",
    "動的計画法（DP）で実装することができる\n",
    "\n",
    "### DPテーブルの初期化\n",
    "DPテーブルの配列サイズは $ K \\times N$になる. ここで, $ K $は状態数（ここでは品詞の数）$ N $（ここでは観測した系列の長さ, つまり文字列の長さ）になる \n",
    "まず, 先頭の隠れ状態の確率分布 $ P(\\bm{z}_0) $ を決定する必要があるが, 品詞付与タスクの場合は明らかに $ P(\\rm{\"BOS\"}) = 1 $でその他の品詞が出る確率は0. （\"BOS\"は先頭の特殊文字）\n",
    "DPテーブルの初期化式は\n",
    "$$\n",
    "    V[0][k] =\n",
    "        \\left\\{\n",
    "            \\begin{array}{ll}\n",
    "                1 & k = \\rm{\"BOS\"} \\\\\n",
    "                0 & \\rm{その他の品詞}\n",
    "            \\end{array}\n",
    "        \\right.\n",
    "\n",
    "$$\n",
    "\n",
    "### DPテーブルの更新\n",
    "`V[i][k]`（入力された文字のi番目の品詞がkである確率の最大値（尤度?））は`V[i - 1]`を使って次のように更新できる\n",
    "$$\n",
    "    V[i][k] = \n",
    "        \\rm{max}\\left\\{\n",
    "            \\begin{array}{ll}\n",
    "                V[i - 1][\\rm{\"BOS\"}] \\\\\n",
    "                V[i - 1][\\rm{\"ADP\"}] \\\\\n",
    "                V[i - 1][\\rm{\"VERB\"}] \\\\\n",
    "                \\cdots \\\\\n",
    "            \\end{array}\n",
    "        \\right.\n",
    "$$\n",
    "\n",
    "### 計算量\n",
    "状態数を`K`, 文字列の長さを`N`とした時, `O(NK)`\n",
    "\n",
    "### 実験\n",
    "三つの文字列で試してみる\n",
    "- `Time flies like an arrow\"`\n",
    "    - 光陰矢の如し\n",
    "    - 時バエは矢を好む\n",
    "- `Book covers like a jacket`\n",
    "    - 本はジャケットのようにカバーしている\n",
    "    - ブックカバーはジャケットのようだ\n",
    "\n",
    "このデータセットが小さいからなのかわからないけど, `like`が前置詞として解釈される\n",
    "あとは正常？かな\n",
    "\n",
    "### 品詞一覧\n",
    "- ADP : 前置詞\n",
    "- CONJ : 接続詞\n",
    "- ADJ : 形容詞\n",
    "- . : 句読点\n",
    "- VERB : 動詞\n",
    "- ADV : 副詞\n",
    "- NUM : 数詞\n",
    "- BOS : 先頭文字（勝手に作った特殊記号）\n",
    "- PRT : 助詞\n",
    "- NOUN : 名詞\n",
    "- DET : 限定詞(theとかanとか)\n",
    "- PRON : 代名詞\n",
    "- X : その他もろもろ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.322601105263117e-18\n",
      "NOUN\n",
      "['BOS', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "V = [{}]\n",
    "path = {}\n",
    "start_p = {\n",
    "    tag: 1 if tag == \"BOS\" else 0 for tag in tag_list\n",
    "}\n",
    "# sample_str = \"Time flies like an arrow\"\n",
    "# sample_str = \"he likes an apple\"\n",
    "sample_str = \"Book covers like a jacket\"\n",
    "words_list = list(map(lambda s: s.lower() ,sample_str.split()))\n",
    "# # 初期化\n",
    "for tag in tag_list:\n",
    "    if tag == \"BOS\":\n",
    "        V[0][tag] = 1\n",
    "    else:\n",
    "        V[0][tag] = 0\n",
    "    path[tag] = [tag]\n",
    "    \n",
    "for index in range(len(words_list)):\n",
    "    V.append({})\n",
    "    newpath = {}\n",
    "    \n",
    "    for cur_tag_state in tag_list:\n",
    "        prob, state = max((V[index][y] * transition_pro[y][cur_tag_state] * cfd[cur_tag_state][words_list[index]], y) for y in tag_list)\n",
    "        V[index + 1][cur_tag_state] = prob\n",
    "        newpath[cur_tag_state] = path[state] + [cur_tag_state]\n",
    "    \n",
    "    path = newpath\n",
    "    \n",
    "(prob, state) = max((V[len(words_list) ][y], y) for y in tag_list)\n",
    "\n",
    "print(prob)\n",
    "print(path[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
